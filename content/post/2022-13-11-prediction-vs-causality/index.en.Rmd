---
title: "Prediction versus causality [2/2]"
author: "Pierre Bauvin"
date: '2022-12-12'
categories: ["Prediction", "Causality"]
tags: ["Prediction model", "Data science", "Causality", "DAG"]
subtitle: 'How prediction may not be what you need'
summary: 'A very good prediction model may be useless, or even worse! With a more subtle example'
header-includes:
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
bibliography: [../../../static/bib/My_bib.bib] 
csl: [../../../static/bib/climate-dynamics.csl]
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(collapse = FALSE, include=FALSE, 
                      echo = FALSE, message = FALSE)

require(SuperLearner)
require(randomForest)
require(xgboost)
require(pROC)
require(ggplot2)
# require(bbplot)
require(dplyr)


```

# Previous post

We saw previously that the inclusion of a variable that is the consequence of both a plausible cause and the outcome of interest (a collider) may lead to very good prediction models, but which may be more than useless! They can actually be misleading. Our example used a variable, "app usage" that is posterior to the others, pancakes-related variables, and may seem like a too obvious case for the sharp minds of my reader.


# A more subtle example: the "M" bias


Let's move together to another area, for the next case study: public health. 

<center>
![](/post/2022-13-11-prediction-vs-causality/healthcare-money.png)
[](https://floridapolitics.com/archives/460264-federal-approval-of-additional-1-1b-in-medicaid-funds-imminent-top-health-officials-say/)
</center>


Let's imagine that the government is ready to put a lot of money to adress the type 2 diabetes issue, and more specifically to  prevent the occurrence of type 2 diabetes. But what to act on? Main known (causal) drivers of type 2 diabetes are genetics (non-instrumental), age (non-instrumental) and obesity (already sufficiently adressed, according to the government). Lets find a new interesting, workable feature that leads to type 2 diabetes, that we can act on!

In this fictional scenario, type 2 diabetes is the consequence of genes, age, BMI, and that's all, so this new driver reseach is destined to find nothing. See figure for the transcription of these hypotheses.

```{r DAG2, echo=FALSE, fig.cap="Simple DAG for diabetes", out.width = '100%'}

# knitr::include_graphics("/post/2022-13-11-prediction-vs-causality/ImageDAG2.png", error = FALSE)

```

![](/post/2022-13-11-prediction-vs-causality/ImageDAG2.png)


However, the government doesn't know this, and has access to a lot of data. Thus, it hires a team of Data Scientist in this quest to find a new feature causing type 2 diabetes. In the government data set, from extensive interview of random individuals, there is data on whether one's mother has diabetes, or not, as well as, why not: one's number of opera visit during childhood. Both totally non-causal with respect to one's diabetes status. However, both are *statistically* related to one's diabetes status, as described by the next DAG: mother's genes influence mother's diabetes status, as well as one's diabetes status (because it influences one's gene), but we don't have genetic data on the government database. Moreover, family income is causing both mother's diabetes (because it impacts mother's BMI) and number of opera visit during childhood, but we don't have access to childhood income either.

```{r}

# http://www.dagitty.net/dags.html

# dag {
# "Family income during childhood" [latent,pos="-0.100,-0.887"]
# "Mother's diabetes" [pos="-0.032,-0.770"]
# "Mother's genes" [latent,pos="0.032,-0.882"]
# "Number of opera visit during childhood" [exposure,pos="-0.100,-0.568"]
# Age [pos="0.082,-0.525"]
# BMI [pos="-0.016,-0.519"]
# Diabetes [outcome,pos="0.034,-0.578"]
# Genes [latent,pos="0.033,-0.724"]
# "Family income during childhood" -> "Mother's diabetes"
# "Family income during childhood" -> "Number of opera visit during childhood"
# "Mother's genes" -> "Mother's diabetes"
# "Mother's genes" -> Genes
# Age -> Diabetes
# BMI -> Diabetes
# Genes -> Diabetes
# }



# knitr::include_graphics("/post/2022-13-11-prediction-vs-causality/ImageDAG3.png", error = FALSE)

```
![](/post/2022-13-11-prediction-vs-causality/ImageDAG3.png)

Similarly as in the previous post, data is generated following this last DAG, and we are going to perform predictions, to find if other features predict diabetes.

```{r}

# set.seed(25112022)
# n <- 1000
# childhood_income <- rnorm(n, mean=1500, sd=200)
# mother_genes <- rnorm(n, mean=0, sd=1)
# bmi <- 20 + rweibull(n=n, shape = 2, scale = 10)
# age <- round(rweibull(n=n, shape = 3, scale = 50))
# mother_diabetes <- 2*mother_genes + childhood_income/1500 + rnorm(n, mean=0, sd=1)
# number_opera <- round(childhood_income/50 - 15 + rnorm(n, mean=1, sd=0.8))
# genes <- (mother_genes + rnorm(n, mean=0, sd=1))/2
# diabetes_score <- genes + bmi/25 + age/50 + rnorm(n, mean=0, sd=1)
# diabetes <- diabetes_score >= 3
# too debug


set.seed(25112022)
n <- 1000
childhood_income <- rnorm(n, mean=0, sd=1)
mother_genes  <- rnorm(n, mean=0, sd=1)
bmi <- rnorm(n, mean=0, sd=1)
age  <- rnorm(n, mean=0, sd=1)
mother_diabetes <- 5*childhood_income + 2*mother_genes + rnorm(n, mean=0, sd=1)
number_opera <- 2*childhood_income + rnorm(n, mean=0, sd=1)
genes <- mother_genes + rnorm(n, mean=0, sd=1)
diabetes_score <- genes + 2*bmi + 2*age + rnorm(n, mean=0, sd=1)
diabetes <- diabetes_score >= 1

# summary(glm(diabetes ~ bmi + age + number_opera, family="binomial"))


data_simulated <- data.frame(diabetes=diabetes,
                             childhood_income=childhood_income,
                             bmi=bmi,
                             age=age,
                             mother_diabete=mother_diabetes,
                             number_opera=number_opera)

```


Again, we build several models to predict the diabetes risk, using all available data: age, bmi, mother's diabetes status and number of opera visits during childhood. On the contrary to the previous analysis, all variables precede  the outcome. The results in terms of AUC are below: 

```{r second-prediction-model-estimation, fig.cap='Performances of diabetes prediction', fig.align='center', fig.pos='H', include=TRUE, warning=FALSE}


model_lm_wrong <- glm(diabetes ~ bmi + age + mother_diabetes + number_opera,
                      data=data_simulated, family=binomial)
model_lm_good <- glm(diabetes ~ bmi + age + number_opera,
                      data=data_simulated, family=binomial)

train_obs <- sample(nrow(data_simulated), round(20*nrow(data_simulated)/100))
x_train <- data_simulated[train_obs, -which(colnames(data_simulated) == "diabetes")]
y_train <- as.numeric(data_simulated[train_obs, "diabetes"])
x_test <- data_simulated[-train_obs, -which(colnames(data_simulated) == "diabetes")]
y_test <- as.numeric(data_simulated[-train_obs, "diabetes"])

learner_libraries <- list("Simple mean"="SL.mean", 
                          "Simple linear"="SL.glm",
                          "Linear with interaction"="SL.glm.interaction",
                          "Linear with LASSO"="SL.glmnet",
                          "Support-vector machine"="SL.svm",
                          "Random forest" ="SL.randomForest",
                          "XGboost"="SL.xgboost")
sl_simplesplit <- SuperLearner(Y = y_train, X = x_train, family = binomial(),
                        method = "method.AUC",
                        SL.library = learner_libraries)

pred <- predict(sl_simplesplit, x_test, 
                onlySL = FALSE)$library.predict
df_auc <- data.frame(modele=names(learner_libraries))
df_auc$auc_estimate <- NA
df_auc$auc_low <- NA
df_auc$auc_upp <- NA
for (i in 1:length(learner_libraries)) {
    
    auc <- ci.auc(y_test, pred[,i]) 
    df_auc$auc_estimate[i] <- auc[2]
    df_auc$auc_low[i] <- auc[1]
    df_auc$auc_upp[i] <- auc[3]
    
}
df_auc$modele <- factor(df_auc$modele, 
                        levels = rev(names(learner_libraries)))
ggplot(df_auc, aes(modele, auc_estimate)) +
    geom_point(size=4) +
    geom_errorbar(aes(ymin=auc_low, ymax=auc_upp), width=0.2) + 
    coord_flip() +
    scale_y_continuous(limits=c(0.5,1)) + 
    labs(x="", y="AUC value", title = "AUC values of prediction") +
    theme_bw() + 
    theme(legend.position = "none")  


```

\

Great, we have again excellent predicting models, such as the simple linear model. With it, we are able to predict diabetes with a discriminatory power (AUC) of 0.93, for the linear model!

Let's look at the relationship between the only operational variable (number of opera visits), and the predicted risk of diabetes, in the best model that we obtain, for a mean individual.


```{r second-prediction-model-predictions, fig.cap='Predicted risks of diabetes', fig.align='center', fig.pos='H', include=TRUE, warning=FALSE}

data_opera_diabetes <- expand.grid(mean(x_train$childhood_income),
                                    mean(x_train$bmi),
                                    mean(x_train$age),
                                    mean(x_train$mother_diabete),
                                    seq(0,20,by=1))
colnames(data_opera_diabetes) <- c("childhood_income",
                                "bmi",
                                "age", 
                                "mother_diabete",
                                "number_opera")
pred <- predict(sl_simplesplit, data_opera_diabetes, 
                onlySL = FALSE)$library.predict
pred <- cbind(pred, data_opera_diabetes)

pred_reshaped <- reshape(pred, direction='long', 
        varying=c("SL.glm_All",
                  "SL.glm.interaction_All",
                  "SL.glmnet_All",
                  "SL.svm_All",
                  "SL.randomForest_All",
                  "SL.xgboost_All"), 
        timevar='modele',
        times=c("SL.glm",
                "SL.glm.interaction",
                "SL.glmnet",
                "SL.svm",
                "SL.randomForest",
                "SL.xgboost"),
        v.names=c("Risk"),
        idvar=c("number_opera"))
pred_reshaped <- pred_reshaped[which(pred_reshaped$modele == "SL.glm"),]
pred_reshaped <- pred_reshaped %>%
    mutate(modele = recode(modele, 
                            "SL.glm"="Simple linear",
                            "SL.glm.interaction"="Linear with interaction",
                            "SL.glmnet"="Linear with LASSO",
                            "SL.svm"="Support-vector machine",
                            "SL.randomForest"="Random forest",
                            "SL.xgboost"="XGboost"))
pred_reshaped$modele <- factor(pred_reshaped$modele, 
                        levels = names(learner_libraries)[-1])
ggplot(pred_reshaped, aes(x = number_opera, y = Risk)) +
    geom_line() +
    # scale_fill_gradient( trans = 'log' ) +
    facet_wrap(~ modele) +
    labs(x="Number of opera visits during childhood", y="Diabetes risk") +
    # scale_fill_gradient2(low = "#67001f", mid="#f7f7f7", high = "#053061", midpoint = 0.4) +
    theme_bw() 

```

\

Amazing; our awesome predicting model tells us that the diabetes risk decreases with the number of opera visits during childhood. From 35% diabetes risk for individuals who never had the chance to visit the opera during childhood, to less than 5% risk for lucky ones with more that 20 opera visits!

The Data Science team reports to the government, that decides to found a national plan for Opera promotion for the youth, hoping to tackle the diabetes issue. Obviously, it isn't going to be a success.

Whereas a Data Scientist who is aware of causal inference, who draws DAGs, reads Hernàn and Pearl, will identify the "M-bias" from the previous DAG. By including the "mother diabetes status" in a model, according to the D-separation rules, a path is open between the number of opera visits (or any marker of family income during childhood) and diabetes, as long as we can't include the "genes" variable (that are often not available).

The answer here is thus to remove the "mother diabetes status" from the analysis, leading to less accurate prediction models (because we loose the indirect informations regarding genes status of our individuals) but more accurate *causal model*, exactly what we want in our settings. In such settings, the effects of age and BMI remains correctly estimated, and the effect of number of opera visits on diabetes falls to null (OR=`r round(exp(-model_lm_good$coefficients["number_opera"]), 2)`, 95%CI `r paste0(round(exp(-confint(model_lm_good)["number_opera",2:1]),2), collapse = "-")`).

\

# Perspectives on causal inference & machine learning


Of course, causal inference doesn't prevent the use of machine learning. It is mainly an injunction to reflect on the goal of the analysis, on the study design and the meaning of features.

Actually, there are several causal methods using state-of-the-art machine learning algorithms to improve the accuracy of causal inference results. The Targeted Maximum Likelihood Estimation method (@vanderLaanRubin) and the Double/Debiased Machine Learning framework (@Chernozhukov) are two very good examples, aiming to estimate point treatment effects, using semi-parametric approach and machine learning algorithms of your choice to predict both of the nuisance parameters (the outcome, and the probability of treatment). Both algorithms are fascinating and are starting to see a widespread use, but their description will be in a future blogpost; see @IvanDiaz for a good first introduction.

\

# References

<div id="refs"></div>

